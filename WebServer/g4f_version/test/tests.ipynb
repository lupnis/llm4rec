{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "from typing import Callable, Dict, List, Optional, Union, Any, Iterator\n",
    "\n",
    "from langchain_community.docstore.document import Document\n",
    "from langchain_community.document_loaders.base import BaseLoader\n",
    "\n",
    "class JSONLoader(BaseLoader):\n",
    "    def __init__(\n",
    "        self,\n",
    "        file_path: Union[str, Path],\n",
    "        content_key: Optional[str] = None,\n",
    "        metadata_func: Optional[Callable[[Dict, Dict], Dict]] = None,\n",
    "        text_content: bool = True,\n",
    "        json_lines: bool = False,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Initializes the JSONLoader with a file path, an optional content key to extract specific content,\n",
    "        and an optional metadata function to extract metadata from each record.\n",
    "        \"\"\"\n",
    "        self.file_path = Path(file_path).resolve()\n",
    "        self._content_key = content_key\n",
    "        self._metadata_func = metadata_func\n",
    "        self._text_content = text_content\n",
    "        self._json_lines = json_lines\n",
    "\n",
    "    def load(self) -> List[Document]:\n",
    "        \"\"\"Load and return documents from the JSON file.\"\"\"\n",
    "        docs: List[Document] = []\n",
    "        if self._json_lines:\n",
    "            with self.file_path.open(encoding=\"utf-8\") as f:\n",
    "                for line in f:\n",
    "                    line = line.strip()\n",
    "                    if line:\n",
    "                        self._parse(line, docs)\n",
    "        else:\n",
    "            self._parse(self.file_path.read_text(encoding=\"utf-8\"), docs)\n",
    "        return docs\n",
    "\n",
    "    def _parse(self, content: str, docs: List[Document]) -> None:\n",
    "        \"\"\"Convert given content to documents.\"\"\"\n",
    "        data = json.loads(content)\n",
    "\n",
    "        # Perform some validation\n",
    "        # This is not a perfect validation, but it should catch most cases\n",
    "        # and prevent the user from getting a cryptic error later on.\n",
    "        if self._content_key is not None:\n",
    "            self._validate_content_key(data)\n",
    "        if self._metadata_func is not None:\n",
    "            self._validate_metadata_func(data)\n",
    "\n",
    "        for i, sample in enumerate(data, len(docs) + 1):\n",
    "            text = self._get_text(sample=sample)\n",
    "            metadata = self._get_metadata(sample=sample, source=str(self.file_path), seq_num=i)\n",
    "            docs.append(Document(page_content=text, metadata=metadata))\n",
    "\n",
    "    def _get_text(self, sample: Any) -> str:\n",
    "        \"\"\"Convert sample to string format\"\"\"\n",
    "        if self._content_key is not None:\n",
    "            content = sample.get(self._content_key)\n",
    "        else:\n",
    "            content = sample\n",
    "\n",
    "        if self._text_content and not isinstance(content, str):\n",
    "            raise ValueError(\n",
    "                f\"Expected page_content is string, got {type(content)} instead. \\\n",
    "                    Set `text_content=False` if the desired input for \\\n",
    "                    `page_content` is not a string\"\n",
    "            )\n",
    "\n",
    "        # In case the text is None, set it to an empty string\n",
    "        elif isinstance(content, str):\n",
    "            return content\n",
    "        elif isinstance(content, dict):\n",
    "            return json.dumps(content) if content else \"\"\n",
    "        else:\n",
    "            return str(content) if content is not None else \"\"\n",
    "\n",
    "    def _get_metadata(self, sample: Dict[str, Any], **additional_fields: Any) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Return a metadata dictionary base on the existence of metadata_func\n",
    "        :param sample: single data payload\n",
    "        :param additional_fields: key-word arguments to be added as metadata values\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        if self._metadata_func is not None:\n",
    "            return self._metadata_func(sample, additional_fields)\n",
    "        else:\n",
    "            return additional_fields\n",
    "\n",
    "    def _validate_content_key(self, data: Any) -> None:\n",
    "        \"\"\"Check if a content key is valid\"\"\"\n",
    "        sample = data.first()\n",
    "        if not isinstance(sample, dict):\n",
    "            raise ValueError(\n",
    "                f\"Expected the jq schema to result in a list of objects (dict), \\\n",
    "                    so sample must be a dict but got `{type(sample)}`\"\n",
    "            )\n",
    "\n",
    "        if sample.get(self._content_key) is None:\n",
    "            raise ValueError(\n",
    "                f\"Expected the jq schema to result in a list of objects (dict) \\\n",
    "                    with the key `{self._content_key}`\"\n",
    "            )\n",
    "\n",
    "    def _validate_metadata_func(self, data: Any) -> None:\n",
    "        \"\"\"Check if the metadata_func output is valid\"\"\"\n",
    "\n",
    "        sample = data.first()\n",
    "        if self._metadata_func is not None:\n",
    "            sample_metadata = self._metadata_func(sample, {})\n",
    "            if not isinstance(sample_metadata, dict):\n",
    "                raise ValueError(\n",
    "                    f\"Expected the metadata_func to return a dict but got \\\n",
    "                        `{type(sample_metadata)}`\"\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PlainTextLoader(BaseLoader):\n",
    "    def __init__(\n",
    "        self,\n",
    "        texts: str\n",
    "    ):\n",
    "       self.texts = texts\n",
    "\n",
    "    def lazy_load(self) -> Iterator[Document]:\n",
    "        metadata = {\"source\": \"plain text\"}\n",
    "        yield from[Document(page_content=text, metadata=metadata) for text in self.texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders.text import TextLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings.ollama import OllamaEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.llms.ollama import Ollama\n",
    "from langchain.chains.conversational_retrieval.base import ConversationalRetrievalChain\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "llm = Ollama(model='qwen:0.5b')\n",
    "embeddings = OllamaEmbeddings(model='qwen:0.5b')\n",
    "\n",
    "documents = PlainTextLoader(['I like games with following tags: \"Action\",\"Simulation\",\"Casual\",\"Single-player\",\"Strategy\",\"Indie\", but i do not like games with the following tags:\"2D\",\"Tactical\",\"Trading Card Game\".']).load()\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "documents = text_splitter.split_documents(documents)\n",
    "vectorstore = Chroma.from_documents(documents, embeddings)\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "\n",
    "# from langchain.chains.retrieval_qa.base import RetrievalQA\n",
    "# chain = RetrievalQA.from_chain_type(llm, retriever=retriever)\n",
    "\n",
    "\n",
    "from langchain.memory import ConversationSummaryMemory,ConversationBufferMemory\n",
    "# memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
    "memory = ConversationBufferMemory(\n",
    "    llm=llm, memory_key=\"chat_history\", return_messages=True)\n",
    "\n",
    "qa = ConversationalRetrievalChain.from_llm(llm, retriever=retriever, memory=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(qa('do i like tactical games?')[\"answer\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_gpu_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
